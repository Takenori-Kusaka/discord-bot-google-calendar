"""ç”Ÿæ´»å½±éŸ¿æƒ…å ±ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆe-Govæ³•ä»¤API + ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰"""

import xml.etree.ElementTree as ET
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import IntEnum
from typing import Optional
from zoneinfo import ZoneInfo

import aiohttp
from bs4 import BeautifulSoup

from ..utils.logger import get_logger

logger = get_logger(__name__)


class TrustLevel(IntEnum):
    """ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«"""

    UNKNOWN = 1  # ä¸æ˜ãƒ»è¦ç¢ºèª
    SINGLE_SOURCE = 2  # å˜ä¸€ã‚µã‚¤ãƒˆ
    NEWS_MAJOR = 3  # å¤§æ‰‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¤‡æ•°
    MULTIPLE_MUNICIPALITIES = 4  # è¤‡æ•°è‡ªæ²»ä½“ã§ç¢ºèª
    OFFICIAL_EGOV = 5  # å®˜å ±ãƒ»e-Gov


TRUST_LABELS = {
    TrustLevel.UNKNOWN: "â“ è¦ç¢ºèª",
    TrustLevel.SINGLE_SOURCE: "âš ï¸ å˜ä¸€ã‚½ãƒ¼ã‚¹",
    TrustLevel.NEWS_MAJOR: "ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ç¢ºèª",
    TrustLevel.MULTIPLE_MUNICIPALITIES: "ğŸ›ï¸ è¤‡æ•°è‡ªæ²»ä½“ç¢ºèª",
    TrustLevel.OFFICIAL_EGOV: "ğŸ“Œ å®˜å ±ç¢ºèª",
}


# å®¶æ—ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
FAMILY_KEYWORDS = [
    "å…ç«¥æ‰‹å½“",
    "å­è‚²ã¦",
    "ä¿è‚²",
    "å¹¼ç¨šåœ’",
    "è‚²å…",
    "å‡ºç”£",
    "å¦Šå¨ ",
    "ä¹³å¹¼å…",
    "åŒ»ç™‚è²»",
    "äºˆé˜²æ¥ç¨®",
    "æ‰¶é¤Š",
    "æ‰€å¾—ç¨",
    "ä½æ°‘ç¨",
    "ç¢ºå®šç”³å‘Š",
    "å¹´æœ«èª¿æ•´",
    "ä½å®…ãƒ­ãƒ¼ãƒ³",
    "ãµã‚‹ã•ã¨ç´ç¨",
    "ç¤¾ä¼šä¿é™º",
    "å¥åº·ä¿é™º",
    "é›‡ç”¨ä¿é™º",
    "ä»‹è­·",
    "è‚²ä¼‘",
    "ç”£ä¼‘",
    "ãƒãƒ£ã‚¤ãƒ«ãƒ‰ã‚·ãƒ¼ãƒˆ",
    "é“è·¯äº¤é€šæ³•",
    "æ•™è‚²",
    "çµ¦é£Ÿ",
    "å­¦æ ¡",
]


@dataclass
class LifeImpactInfo:
    """ç”Ÿæ´»å½±éŸ¿æƒ…å ±"""

    title: str
    description: str
    source: str
    source_url: str
    trust_level: TrustLevel
    effective_date: Optional[datetime] = None
    deadline: Optional[datetime] = None
    requires_action: bool = False
    fetched_at: datetime = field(
        default_factory=lambda: datetime.now(ZoneInfo("Asia/Tokyo"))
    )

    def format_for_notification(self) -> str:
        """é€šçŸ¥ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        trust_label = TRUST_LABELS.get(self.trust_level, "")
        lines = [f"{trust_label} **{self.title}**", f"  {self.description}"]

        if self.effective_date:
            lines.append(f"  æ–½è¡Œæ—¥: {self.effective_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}")

        if self.deadline:
            lines.append(f"  â° æœŸé™: {self.deadline.strftime('%Yå¹´%mæœˆ%dæ—¥')}")

        if self.requires_action:
            lines.append("  ğŸ“ æ‰‹ç¶šããŒå¿…è¦ã§ã™")

        lines.append(f"  å‡ºå…¸: {self.source}")

        return "\n".join(lines)


class LifeInfoClient:
    """ç”Ÿæ´»å½±éŸ¿æƒ…å ±ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    # e-Govæ³•ä»¤API Version 1ã®ãƒ™ãƒ¼ã‚¹URL
    # å‚è€ƒ: https://laws.e-gov.go.jp/docs/law-data-basic/8529371-law-api-v1/
    EGOV_BASE_URL = "https://elaws.e-gov.go.jp/api/1"

    def __init__(self, timezone: str = "Asia/Tokyo"):
        """åˆæœŸåŒ–

        Args:
            timezone: ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
        """
        self.timezone = timezone
        logger.info("Life info client initialized")

    async def get_updated_laws(self, days: int = 7) -> list[LifeImpactInfo]:
        """æœ€è¿‘ã®æ³•ä»¤æ›´æ–°ã‚’å–å¾—

        Args:
            days: ä½•æ—¥å‰ã‹ã‚‰ã®æ›´æ–°ã‚’å–å¾—ã™ã‚‹ã‹

        Returns:
            list[LifeImpactInfo]: æ³•ä»¤æ›´æ–°ãƒªã‚¹ãƒˆ
        """
        # e-Govæ³•ä»¤API Version 1ã®æ³•ä»¤ä¸€è¦§ã‚’å–å¾—
        # ã‚«ãƒ†ã‚´ãƒª: 1=å…¨ã¦, 2=æ†²æ³•ãƒ»æ³•å¾‹, 3=æ”¿ä»¤ãƒ»å‹…ä»¤, 4=åºœçœä»¤
        url = f"{self.EGOV_BASE_URL}/lawlists/2"  # æ†²æ³•ãƒ»æ³•å¾‹

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=30) as response:
                    if response.status != 200:
                        logger.warning(f"e-Gov API error: {response.status}")
                        return []

                    xml_text = await response.text()
                    return self._parse_law_updates(xml_text, days)

        except Exception as e:
            logger.error(f"Failed to fetch law updates: {e}")
            return []

    def _parse_law_updates(
        self, xml_text: str, days: int = 30
    ) -> list[LifeImpactInfo]:
        """XMLå½¢å¼ã®æ³•ä»¤æ›´æ–°ã‚’ãƒ‘ãƒ¼ã‚¹

        Args:
            xml_text: XMLå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            days: ä½•æ—¥ä»¥å†…ã®æ›´æ–°ã‚’å¯¾è±¡ã¨ã™ã‚‹ã‹

        Returns:
            list[LifeImpactInfo]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸæ³•ä»¤æ›´æ–°ãƒªã‚¹ãƒˆ
        """
        results = []
        cutoff_date = datetime.now(ZoneInfo(self.timezone)) - timedelta(days=days)

        try:
            root = ET.fromstring(xml_text)

            # æ³•ä»¤æƒ…å ±ã‚’æŠ½å‡ºï¼ˆLawNameListInfoæ§‹é€ ã«å¯¾å¿œï¼‰
            for law_info in root.findall(".//LawNameListInfo"):
                law_name = law_info.findtext("LawName", "")
                law_no = law_info.findtext("LawNo", "")
                law_id = law_info.findtext("LawId", "")
                promulgation_date = law_info.findtext("PromulgationDate", "")

                # å®¶æ—é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if not self._is_family_relevant(law_name):
                    continue

                # æ–½è¡Œæ—¥ã‚’ãƒ‘ãƒ¼ã‚¹
                effective_date = None
                if promulgation_date:
                    try:
                        effective_date = datetime.strptime(
                            promulgation_date, "%Y%m%d"
                        ).replace(tzinfo=ZoneInfo(self.timezone))
                    except ValueError:
                        pass

                # æ³•ä»¤è©³ç´°URL
                detail_url = f"https://laws.e-gov.go.jp/law/{law_id}" if law_id else "https://laws.e-gov.go.jp/"

                info = LifeImpactInfo(
                    title=law_name,
                    description=f"æ³•ä»¤ç•ªå·: {law_no}",
                    source="e-Govæ³•ä»¤æ¤œç´¢",
                    source_url=detail_url,
                    trust_level=TrustLevel.OFFICIAL_EGOV,
                    effective_date=effective_date,
                )
                results.append(info)

            logger.info(f"Parsed {len(results)} family-relevant laws")

        except ET.ParseError as e:
            logger.error(f"Failed to parse XML: {e}")

        return results

    def _is_family_relevant(self, text: str) -> bool:
        """ãƒ†ã‚­ã‚¹ãƒˆãŒå®¶æ—ã«é–¢é€£ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯

        Args:
            text: ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            bool: å®¶æ—é–¢é€£ã§ã‚ã‚Œã°True
        """
        return any(keyword in text for keyword in FAMILY_KEYWORDS)

    async def get_kizugawa_news(self) -> list[LifeImpactInfo]:
        """æœ¨æ´¥å·å¸‚ã®å­è‚²ã¦é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—

        Returns:
            list[LifeImpactInfo]: ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ
        """
        url = "https://www.city.kizugawa.lg.jp/kosodate/"

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=30) as response:
                    if response.status != 200:
                        logger.warning(f"Kizugawa city site error: {response.status}")
                        return []

                    html = await response.text()
                    return self._parse_kizugawa_news(html, url)

        except Exception as e:
            logger.error(f"Failed to fetch Kizugawa news: {e}")
            return []

    def _parse_kizugawa_news(self, html: str, base_url: str) -> list[LifeImpactInfo]:
        """æœ¨æ´¥å·å¸‚ã‚µã‚¤ãƒˆã®HTMLã‚’ãƒ‘ãƒ¼ã‚¹

        Args:
            html: HTMLãƒ†ã‚­ã‚¹ãƒˆ
            base_url: ãƒ™ãƒ¼ã‚¹URL

        Returns:
            list[LifeImpactInfo]: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ
        """
        results = []
        soup = BeautifulSoup(html, "html.parser")

        # æ–°ç€æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        # æ³¨: å®Ÿéš›ã®ã‚µã‚¤ãƒˆæ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦
        news_items = soup.find_all("li", class_="news-item") or soup.find_all(
            "div", class_="news-item"
        )

        # ä»£æ›¿: ä¸€èˆ¬çš„ãªãƒªãƒ³ã‚¯ãƒªã‚¹ãƒˆã‚’æ¢ã™
        if not news_items:
            news_section = soup.find("div", class_="news") or soup.find(
                "ul", class_="news-list"
            )
            if news_section:
                news_items = news_section.find_all("li")

        for item in news_items[:10]:  # æœ€å¤§10ä»¶
            link = item.find("a")
            if not link:
                continue

            title = link.get_text(strip=True)
            href = link.get("href", "")

            if not title or not self._is_family_relevant(title):
                continue

            # URLã‚’æ­£è¦åŒ–
            if href and not href.startswith("http"):
                href = f"https://www.city.kizugawa.lg.jp{href}"

            info = LifeImpactInfo(
                title=title,
                description="æœ¨æ´¥å·å¸‚ã‹ã‚‰ã®ãŠçŸ¥ã‚‰ã›",
                source="æœ¨æ´¥å·å¸‚",
                source_url=href or base_url,
                trust_level=TrustLevel.MULTIPLE_MUNICIPALITIES,
            )
            results.append(info)

        logger.info(f"Parsed {len(results)} Kizugawa news items")
        return results

    async def get_all_life_info(self) -> list[LifeImpactInfo]:
        """å…¨ã¦ã®ç”Ÿæ´»å½±éŸ¿æƒ…å ±ã‚’å–å¾—

        Returns:
            list[LifeImpactInfo]: å…¨æƒ…å ±ãƒªã‚¹ãƒˆï¼ˆä¿¡é ¼æ€§é †ã«ã‚½ãƒ¼ãƒˆï¼‰
        """
        all_info = []

        # e-Govæ³•ä»¤æ›´æ–°
        law_updates = await self.get_updated_laws()
        all_info.extend(law_updates)

        # æœ¨æ´¥å·å¸‚ãƒ‹ãƒ¥ãƒ¼ã‚¹
        kizugawa_news = await self.get_kizugawa_news()
        all_info.extend(kizugawa_news)

        # å›ºå®šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æƒ…å ±
        scheduled_info = self._get_scheduled_info()
        all_info.extend(scheduled_info)

        # ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã§ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„é †ï¼‰
        all_info.sort(key=lambda x: x.trust_level, reverse=True)

        logger.info(f"Total life info items: {len(all_info)}")
        return all_info

    def _get_scheduled_info(self) -> list[LifeImpactInfo]:
        """å›ºå®šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é‡è¦æƒ…å ±ã‚’å–å¾—

        Returns:
            list[LifeImpactInfo]: å›ºå®šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ãƒªã‚¹ãƒˆ
        """
        now = datetime.now(ZoneInfo(self.timezone))
        results = []

        # ç¢ºå®šç”³å‘Šã‚·ãƒ¼ã‚ºãƒ³ï¼ˆ1æœˆä¸­æ—¬ã€œ3æœˆä¸­æ—¬ï¼‰
        if now.month == 1 and now.day >= 10:
            results.append(
                LifeImpactInfo(
                    title="ç¢ºå®šç”³å‘Šã®æº–å‚™ã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†",
                    description="åŒ»ç™‚è²»æ§é™¤ã€ä½å®…ãƒ­ãƒ¼ãƒ³æ§é™¤ã€ãµã‚‹ã•ã¨ç´ç¨ã®æ›¸é¡ã‚’æº–å‚™ã—ã¦ãã ã•ã„",
                    source="å›½ç¨åº",
                    source_url="https://www.nta.go.jp/taxes/shiraberu/shinkoku/tokushu/index.htm",
                    trust_level=TrustLevel.OFFICIAL_EGOV,
                    deadline=datetime(now.year, 3, 15, tzinfo=ZoneInfo(self.timezone)),
                    requires_action=True,
                )
            )

        # å¹´åº¦æ›¿ã‚ã‚Šå‰ï¼ˆ3æœˆï¼‰
        if now.month == 3:
            results.append(
                LifeImpactInfo(
                    title="ç¤¾ä¼šä¿é™ºæ–™ç‡ã®å¤‰æ›´ã«æ³¨æ„",
                    description="4æœˆã‹ã‚‰é›‡ç”¨ä¿é™ºæ–™ç‡ç­‰ãŒå¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
                    source="åšç”ŸåŠ´åƒçœ",
                    source_url="https://www.mhlw.go.jp/",
                    trust_level=TrustLevel.OFFICIAL_EGOV,
                    effective_date=datetime(
                        now.year, 4, 1, tzinfo=ZoneInfo(self.timezone)
                    ),
                )
            )

        # ãµã‚‹ã•ã¨ç´ç¨ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼ï¼ˆ11æœˆã€œ12æœˆï¼‰
        if now.month in [11, 12]:
            results.append(
                LifeImpactInfo(
                    title="ãµã‚‹ã•ã¨ç´ç¨ã®å¹´å†…å¯„é™„ã‚’å¿˜ã‚Œãšã«",
                    description="ä»Šå¹´ã®æ§é™¤ã‚’å—ã‘ã‚‹ã«ã¯12æœˆ31æ—¥ã¾ã§ã«å¯„é™„ãŒå¿…è¦ã§ã™",
                    source="ç·å‹™çœ",
                    source_url="https://www.soumu.go.jp/main_sosiki/jichi_zeisei/czaisei/czaisei_seido/furusato/about/",
                    trust_level=TrustLevel.OFFICIAL_EGOV,
                    deadline=datetime(
                        now.year, 12, 31, tzinfo=ZoneInfo(self.timezone)
                    ),
                    requires_action=True,
                )
            )

        return results

    def format_for_weekly_notification(
        self, info_list: list[LifeImpactInfo]
    ) -> str:
        """é€±æ¬¡é€šçŸ¥ç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

        Args:
            info_list: ç”Ÿæ´»å½±éŸ¿æƒ…å ±ãƒªã‚¹ãƒˆ

        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸé€šçŸ¥æ–‡
        """
        if not info_list:
            return "ä»Šé€±ã¯ç‰¹ç­†ã™ã¹ãæ³•æ”¹æ­£ãƒ»åˆ¶åº¦å¤‰æ›´ã®æƒ…å ±ã¯ã”ã–ã„ã¾ã›ã‚“ã€‚"

        lines = ["ã€ä»Šé€±ã®ç”Ÿæ´»å½±éŸ¿æƒ…å ±ã€‘"]

        for info in info_list[:5]:  # æœ€å¤§5ä»¶
            lines.append("")
            lines.append(info.format_for_notification())

        lines.append("")
        lines.append(
            "â€» è©³ç´°ã¯å„å…¬å¼ã‚µã‚¤ãƒˆã§ã”ç¢ºèªãã ã•ã„ã€‚æƒ…å ±ã®æ­£ç¢ºæ€§ã¯ä¿è¨¼ã§ãã¾ã›ã‚“ã€‚"
        )

        return "\n".join(lines)
